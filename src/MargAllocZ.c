/**********************************	FUNCTION:   MargAllocZ		AUTHOR:  Eric C. Anderson  (University of Washington)  eriq@cqs.washington.edu		DATE:  Revised 9/28/2000		PURPOSE:		This is a generic function which updates the allocation variables (z's) between 		two components in a finite mixture, having marginalized over the beta 		prior on the mixing proportions. 		INPUT:		int NumZs		-->		number of observations which will have their z's reallocated		int *idx	-->		an array of the indices of the observations under consideration.  Note							that in the function idx[t] will give the index of the observation		int Comp0,Comp1 	-->	The indices of the component that will be considered "0" or "1".  		double Alpha,Beta 	-->	the parameters of the prior on the mixing proportions.  If								the mixture has more components, these are just obtained								by marginalizing that Dirichlet prior down to a beta								prior on the two components of interest		(*MAZ_DataProb())		-->  Pointer to a function		MAZ_var_struct *Vars	-->	Pointer to a structure which holds pointers to									the data and the parameters, so that these may									be accessed by the function MAZ_DataProb.			OUTPUT:		int *NewAlloc	-->	output parameter in which the updated allocations of the 							z's are stored.  You have to have memory allocated to this already,							enough for NumZs, basically.		RETURNS:		Function returns a double variable which is the log of the data in the two 		components given the current values of the component specific parameters.  			REQUIRES		This function requires an area in memory in which to perform the computations.		Rather than keep allocating and freeing this memory, this function relies on		a space in global memory which should have been previous allocated and named		gBaumProbs.  This is a double*** of size [NumZs][NumZs+1][2].				Also requires that you have defined a structure called MAZ_var_struct through		which MAZ_DataProb may access the variables necessary to compute the probability of		each observations given its z and the associated component-specific parameters.  				**********************************/#include <stdlib.h>#include <stdio.h>#include <math.h>#include "ECA_MemAlloc.h"#include "MCTypesEtc.h"#include "MathStatRand.h"#include "ranlib.h"#include "GFMCMC.h"#include "GFMCMC_DrawingUtilities.h"#include "NewHybrids.h"#include "MAZ4NewHybs.h"#include "ECA_MemAlloc.h" double MargAllocZ(	int NumZs,	int *idx,	int Comp0,	int Comp1,	double Alpha,	double Beta,	double (*MAZ_DataProb)(MAZ_var_struct *Vars,int t,int j), 	double (*RandUnif)(),	MAZ_var_struct *Vars,	int *NewAlloc	){ 	int t,d;  // t is "time", and d records the number of 1's by time t 	double w,b,c;  // "initial number of white balls (1's), black balls, and a constant  				   // c = the number of balls that get added to the urn on each draw.   	double normo;  // for normalizing probability dsns.  	double grand_normo = 1.0;  // this will accumulate the product of all the intermediary normalizing 							   // constants, and so will become the probabability of the observations 							   // which will be returned by the function.   	double rando;  // to store a uniform(0,1) random variable. 	int realized_d,realized_z,zi; 	double cumul;  // to store cumulative sums during the backward step 	double temp_numer,temp_denom; 	int CompArray[2]; 	 	// first compute the parameters of a corresponding urn model.  This depends on the  	// parameters of the beta distribution: 	w = (double)NumZs; 	c = w/Alpha; 	b = Beta * c; 	 	 	 	// FORWARD STEP, LOOPING OVER t 	for(t=0;t<NumZs;t++)  { 		// initialize the first values.  Note that if it is white ([x][x][1], then d 		// must be one.  etc.)   		if(t==0)  { 			gBaumProbs[t][0][0] = b/(b+w); 			gBaumProbs[t][1][1] = w/(b+w); 			gBaumProbs[t][1][0] = 0.0; 			gBaumProbs[t][0][1] = 0.0; 		} 		 		else {  // otherwise the prob of different (z,d)'s depends on what came before 			for(d=0;d<t+2;d++)  { 			 				// do the outcome with z_t = 0 				if(d<t+1) {	 				gBaumProbs[t][d][0] = 	 					(gBaumProbs[t-1][d][0] + gBaumProbs[t-1][d][1]) * 	 					( ( b + (t-d)*c) / (b + w + t * c) ); 				} 				else { 					gBaumProbs[t][d][0] = 0.0; 				} 				 				 				// do the outcome with z_t = 1; 				if(d>0) {	 				gBaumProbs[t][d][1] = 	 					(gBaumProbs[t-1][d-1][0] + gBaumProbs[t-1][d-1][1]) * 	 					( ( w + (d-1)*c) / (b + w + t * c) ); 				} 				else { 					gBaumProbs[t][d][1] = 0.0; 				} 			} 			 		} 		 		 		// now, regardless of whether t=0 or t>0, we are going to need to add in the 		// probability of the data.  We have P(z,d|y_0,...,y_{t-1}) at the current t, 		// but we want to update that to be  P(z,d|y_0,...,y_t).  We do this by multiplying 		// each current entry by P(Y_t|z,d) (this gives us the joint probabilities) and then 		// normalizing them so that they sum to one over all z and d.  P(Y_t|z,d) is given  		// by the function pointed to by MAZ_DataProb 		 		normo = 0.0;   // initialize to accumulate a sum. 		for(d=0;d<t+2;d++)  { 		 			gBaumProbs[t][d][0] *= (*MAZ_DataProb)(Vars,idx[t],Comp0); 			gBaumProbs[t][d][1] *= (*MAZ_DataProb)(Vars,idx[t],Comp1);	 			 			// add these to the normalizing constant 			normo += gBaumProbs[t][d][0] + gBaumProbs[t][d][1]; 		} 		 		// now go back and normalize all those so each cell really contains a conditional probability 		for(d=0;d<t+2;d++)  {			gBaumProbs[t][d][0] /= normo;			gBaumProbs[t][d][1] /= normo;		}				grand_normo *= normo;  // what we want is the product of all those normalizing constants. 	} 	 	// having gotten through that loop we have now established some wonderful things:	//	gBaumProbs[t] contains P(z,d|y_0,...,y_t) for all t---these quantities will	//	be used later for getting a realization of the z's.	//	grand_normo at the very end holds the value of the marginal probability P(Y)  this	//	we will return after realizing new values for the z's!		// NOW STARTING THE BACKWARD STEP:	// first put the Component Indices in CompArray:	CompArray[0] = Comp0;	CompArray[1] = Comp1; 	for(t=NumZs-1;t>=0;t--)  {  // cycle backward over "time" realizing (z,d)'s and then 								// updating for t-1 as appropriate 		  		// to draw the first (z,d) at time NumZs-1 we cycle over all possibilities 		// cycle over all the (z,d)'s and choose one based on rando 		if(t==NumZs-1)  { 			 		// draw a random number between 0 and 1 using a pointer to whatever you happen to	 		// be using to generate uniform(0,1) random deviates	 		rando = (*RandUnif)();	 		cumul = 0.0;  	 			 		for(d=0;d<t+2;d++)  {	 			for(zi=0;zi<2;zi++)  {	 				cumul += gBaumProbs[t][d][zi];	 				if(cumul > rando) {	 					realized_d = d;	 					realized_z = zi;	 					// make the assignment to NewAlloc	 					NewAlloc[t] = CompArray[zi];	 						 					d = t+2;  // so it will get out of the loop over d	 					break;  	 				}	 			}	 		}	 	}	 	else {  // otherwise we need merely cycle over a much smaller set of values which	 			// are dictated by the values of z and d that were realized in the last iteration.	 		rando = (double)(*RandUnif)();	 			 		// the only d that fits is either the realized_d (if realized_z==0) or	 		// realized_d - 1 (if realized_z == 1).  We may as well reset the 	 		// value of realized_d here to reflect that	 		realized_d = realized_d - realized_z;	 			 		if(rando < gBaumProbs[t][realized_d][0]   ||	 				  gBaumProbs[t][realized_d][0] == 1.0   )  {  // must add this as a stop-gap measure	 				  											  // because (*RandUnif)() may once in a blue moon	 				  											  // returned 1.00000000000.  Stupid things!				realized_z = 0;	 		}	 		else {				realized_z = 1;	 		}	 			 		// make the assignment to New Alloc:			NewAlloc[t] = CompArray[realized_z];	 	} 		 		 		// now, based on the realized_z and realized_d we must update the conditional 		// probabilities at t-1, so long as t-1 is not zero... 		if(t>0)  { 			 			// note that there are only two values of (d,z) at t-1 that could get you in 			// one step to realized_d and realized_z at time t.  Thus given those realized 			// values the conditional probabilities of all those other (z,d)'s which are 			// incompatible are zero.  However, we need not set them all to 0.0, as we will just 			// be ignoring them, since we cycle over the "much smaller set" as commented above 			 			// if realized_z = 0, then it was a black ball drawn after drawing t - realized_d 			// black balls previously. 			if(realized_z==0) { 				temp_numer = b + ((double)(t - realized_d) * c); 			} 			else {  // otherwise it was a white ball drawn after realized_d - 1 other white balls 				temp_numer = w + ((double)(realized_d - 1) * c); 			} 			 			// the denominator only depends on t 			temp_denom = b + w + ( (double)t * c); 			 			normo = 0.0;  // initialize to accumulate a sum 			 			// form the joint probabilities of the previous (z,d)'s conditional on all the 			// previous y's and the current (z,d) 			gBaumProbs[t-1][realized_d - realized_z][0] *= (temp_numer / temp_denom); 			gBaumProbs[t-1][realized_d - realized_z][1] *= (temp_numer / temp_denom); 			 			normo = gBaumProbs[t-1][realized_d - realized_z][0] +  					gBaumProbs[t-1][realized_d - realized_z][1]; 					 			// now, make those joint probabilities conditional probabilities 			gBaumProbs[t-1][realized_d - realized_z][0] /= normo; 			gBaumProbs[t-1][realized_d - realized_z][1] /= normo; 		 		 		} 		 	} 		return(grand_normo);  }          